{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a program to implement perceptron using McCulloch Pitt’s model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate using McCulloch-Pitts Model:\n",
      "Input: [0 0] -> Output: 0 (Expected: 0)\n",
      "Input: [0 1] -> Output: 0 (Expected: 0)\n",
      "Input: [1 0] -> Output: 0 (Expected: 0)\n",
      "Input: [1 1] -> Output: 1 (Expected: 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the inputs and expected outputs for the AND gate\n",
    "inputs = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "expected_outputs = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Define weights and threshold\n",
    "weights = np.array([1, 1])  # Initial weights\n",
    "threshold = 1.5\n",
    "\n",
    "# McCulloch-Pitts Perceptron Function\n",
    "def perceptron(x, weights, threshold):\n",
    "    # Calculate weighted sum\n",
    "    weighted_sum = np.dot(x, weights)\n",
    "    # Apply threshold\n",
    "    return 1 if weighted_sum >= threshold else 0\n",
    "\n",
    "# Test the Perceptron on each input and print results\n",
    "print(\"AND Gate using McCulloch-Pitts Model:\")\n",
    "for i in range(len(inputs)):\n",
    "    output = perceptron(inputs[i], weights, threshold)\n",
    "    print(f\"Input: {inputs[i]} -> Output: {output} (Expected: {expected_outputs[i]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a program to implement AND & OR gates using Hebbian learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate:\n",
      "Input: [1 1], Output: 1\n",
      "Input: [ 1 -1], Output: -1\n",
      "Input: [-1  1], Output: -1\n",
      "Input: [-1 -1], Output: -1\n",
      "OR Gate:\n",
      "Input: [1 1], Output: 1\n",
      "Input: [ 1 -1], Output: 1\n",
      "Input: [-1  1], Output: 1\n",
      "Input: [-1 -1], Output: -1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs and step function\n",
    "INPUTS = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])\n",
    "\n",
    "def step_function(sum): return 1 if sum >= 0 else -1\n",
    "\n",
    "def calculate_output(weights, instance, bias): return step_function(np.dot(instance, weights) + bias)\n",
    "\n",
    "# Hebbian Learning Algorithm\n",
    "def hebb(outputs):\n",
    "    weights, bias = np.zeros(2), 0  # Initialize weights and bias\n",
    "    for i in range(len(outputs)):\n",
    "        weights += INPUTS[i] * outputs[i]\n",
    "        bias += outputs[i]\n",
    "    return weights, bias\n",
    "\n",
    "# Train, test, and print results for both AND and OR gates\n",
    "def train_and_print(gate_name, outputs):\n",
    "    weights, bias = hebb(outputs)\n",
    "    print(f\"{gate_name.upper()} Gate:\")\n",
    "    for input_vec in INPUTS:\n",
    "        output = calculate_output(weights, input_vec, bias)\n",
    "        print(f\"Input: {input_vec}, Output: {output}\")\n",
    "\n",
    "# AND and OR gate outputs\n",
    "and_outputs = np.array([1, -1, -1, -1])\n",
    "or_outputs = np.array([1, 1, 1, -1])\n",
    "\n",
    "# Print results for both gates\n",
    "train_and_print(\"AND\", and_outputs)\n",
    "train_and_print(\"OR\", or_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a program to implement Crab Classification using pattern net.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.00%\n",
      "The predicted species for the new crab is: Orange\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset (100 crabs: shell width, claw size, weight)\n",
    "np.random.seed(123)  # New seed for better class separation\n",
    "blue_crabs = np.random.normal([5.4, 3.1, 0.35], 0.4, (50, 3))\n",
    "orange_crabs = np.random.normal([6.2, 3.6, 0.55], 0.4, (50, 3))\n",
    "data = np.vstack((blue_crabs, orange_crabs))\n",
    "labels = np.array([0] * 50 + [1] * 50)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the Pattern Net (MLP)\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(8, 8),  # Increased hidden units for better learning\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.01,  # Slightly increased learning rate for faster convergence\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict species for a new crab\n",
    "new_crab = np.array([[5.9, 3.3, 0.5]])\n",
    "prediction = model.predict(new_crab)\n",
    "species = [\"Blue\", \"Orange\"]\n",
    "print(f\"The predicted species for the new crab is: {species[prediction[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a program to implement Wine Classification using Back propagation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='sgd', learning_rate_init=0.01, max_iter=1000, random_state=42)\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a program to implement Jacobian matrix and Hessian matrix in neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian: [2. 4.]\n",
      "Hessian: [[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Define the function f(x, y)\n",
    "def func(x, y):\n",
    "    return x**2 + y**2\n",
    "# Compute Jacobian (first derivatives)\n",
    "def compute_jacobian(x, y):\n",
    "    df_dx = 2 * x  # ∂f/∂x\n",
    "    df_dy = 2 * y  # ∂f/∂y\n",
    "    return np.array([df_dx, df_dy])\n",
    "# Compute Hessian (second derivatives)\n",
    "def compute_hessian(x, y):\n",
    "    d2f_dx2 = 2  # ∂²f/∂x²\n",
    "    d2f_dy2 = 2  # ∂²f/∂y²\n",
    "    d2f_dxdy = 0  # ∂²f/∂x∂y\n",
    "    d2f_dydx = 0  # ∂²f/∂y∂x\n",
    "    return np.array([[d2f_dx2, d2f_dxdy],\n",
    "                     [d2f_dydx, d2f_dy2]])\n",
    "# Example values\n",
    "x_val, y_val = 1.0, 2.0\n",
    "# Compute Jacobian and Hessian\n",
    "jacobian = compute_jacobian(x_val, y_val)\n",
    "hessian = compute_hessian(x_val, y_val)\n",
    "print(\"Jacobian:\", jacobian)\n",
    "print(\"Hessian:\", hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a program to implement classification of linearly separable Data with a LMS algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights: [-0.06145498  1.01651104], Bias: -2.1441048607297626, Predictions: [ 1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data and labels\n",
    "X = np.array([[2, 3], [1, 1], [2, 1], [3, 3], [2, 2]])\n",
    "y = np.array([1, -1, -1, 1, -1])\n",
    "\n",
    "# LMS algorithm\n",
    "w, b, lr = np.zeros(2), 0, 0.01\n",
    "for _ in range(1000):\n",
    "    for i in range(len(X)):\n",
    "        y_pred = np.dot(X[i], w) + b\n",
    "        error = y[i] - y_pred\n",
    "        w += lr * error * X[i]\n",
    "        b += lr * error\n",
    "\n",
    "# Prediction\n",
    "pred = np.sign(np.dot(X, w) + b)\n",
    "print(f\"Final Weights: {w}, Bias: {b}, Predictions: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a program to analyze Long Short Term Memory for weather forecast Data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New hidden state: [-0.06776435]\n",
      "New cell state: [-0.14152555]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simple LSTM cell forward pass (single timestep)\n",
    "def simple_lstm(x, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc):\n",
    "    z = np.concatenate((x, h_prev))  # Concatenate input and previous hidden state\n",
    "\n",
    "    f = sigmoid(np.dot(Wf, z) + bf)  # Forget gate\n",
    "    i = sigmoid(np.dot(Wi, z) + bi)  # Input gate\n",
    "    o = sigmoid(np.dot(Wo, z) + bo)  # Output gate\n",
    "    c_tilde = np.tanh(np.dot(Wc, z) + bc)  # Candidate cell state\n",
    "\n",
    "    c = f * c_prev + i * c_tilde  # New cell state\n",
    "    h = o * np.tanh(c)  # New hidden state\n",
    "\n",
    "    return h, c\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example data: a simple sine wave\n",
    "x = np.array([0.5])  # Input at time step t\n",
    "h_prev = np.zeros(1)  # Initial hidden state\n",
    "c_prev = np.zeros(1)  # Initial cell state\n",
    "\n",
    "# Random LSTM weights and biases for a single hidden unit\n",
    "Wf = np.random.randn(1, 2)  # Forget gate weight\n",
    "Wi = np.random.randn(1, 2)  # Input gate weight\n",
    "Wo = np.random.randn(1, 2)  # Output gate weight\n",
    "Wc = np.random.randn(1, 2)  # Candidate cell state weight\n",
    "\n",
    "bf = np.zeros(1)  # Forget gate bias\n",
    "bi = np.zeros(1)  # Input gate bias\n",
    "bo = np.zeros(1)  # Output gate bias\n",
    "bc = np.zeros(1)  # Cell state bias\n",
    "\n",
    "# Forward pass through the LSTM\n",
    "h, c = simple_lstm(x, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc)\n",
    "\n",
    "# Output the results\n",
    "print(\"New hidden state:\", h)\n",
    "print(\"New cell state:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a program to analyze and evaluate Recurrent Neural Network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [1], Actual class: [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simple RNN parameters\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "seq_length = 4\n",
    "\n",
    "# Random data\n",
    "X = np.random.randn(seq_length, input_size)\n",
    "y = np.random.randint(0, output_size, size=(1,))\n",
    "\n",
    "# Initialize weights and biases\n",
    "Wh = np.random.randn(hidden_size, hidden_size)\n",
    "Wx = np.random.randn(input_size, hidden_size)\n",
    "Wy = np.random.randn(hidden_size, output_size)\n",
    "bh = np.zeros((1, hidden_size))\n",
    "by = np.zeros((1, output_size))\n",
    "\n",
    "# Forward pass\n",
    "h = np.zeros((1, hidden_size))\n",
    "for t in range(seq_length):\n",
    "    h = np.tanh(X[t].dot(Wx) + h.dot(Wh) + bh)  # RNN step\n",
    "output = h.dot(Wy) + by  # Output layer\n",
    "pred = np.argmax(output, axis=1)\n",
    "\n",
    "print(f\"Predicted class: {pred}, Actual class: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a program to analyze Image Net, Google Net, ResNet convolution Neural Networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution Output: [[-5.24037967  1.42180958 11.42118315]\n",
      " [ 1.56246356 -1.09552081  0.63103344]\n",
      " [-1.61880228  0.97691272  0.86265481]]\n",
      "ReLU Output: [[ 0.          1.42180958 11.42118315]\n",
      " [ 1.56246356  0.          0.63103344]\n",
      " [ 0.          0.97691272  0.86265481]]\n",
      "Max Pooling Output: 1.5624635555224768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Random 5x5 input and 3x3 kernel\n",
    "X = np.random.randn(5, 5)\n",
    "W = np.random.randn(3, 3)\n",
    "\n",
    "# Convolution operation (without padding, stride = 1)\n",
    "conv_out = np.array([[np.sum(X[i:i+3, j:j+3] * W) for j in range(3)] for i in range(3)])\n",
    "\n",
    "# ReLU activation\n",
    "relu_out = np.maximum(0, conv_out)\n",
    "\n",
    "# Max pooling (2x2)\n",
    "pool_out = np.max(relu_out[:2, :2])\n",
    "\n",
    "print(\"Convolution Output:\", conv_out)\n",
    "print(\"ReLU Output:\", relu_out)\n",
    "print(\"Max Pooling Output:\", pool_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "10. Write a program to analyze use of Gated Recurrent Units to predict the Stock prices based on historic data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Vector (X): [ 0.5 -0.2  0.1]\n",
      "Previous Hidden State (h_prev): [0. 0.]\n",
      "Update Gate (z): [0.34192562 0.25581237]\n",
      "Reset Gate (r): [0.67967523 0.64679233]\n",
      "Candidate Hidden State (h_tilde): [-0.37587208  0.44169546]\n",
      "New Hidden State (h): [-0.12852029  0.11299116]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  # Sigmoid function\n",
    "\n",
    "# GRU parameters (random initialization)\n",
    "input_size = 3  # Size of input vector\n",
    "hidden_size = 2  # Size of hidden state\n",
    "\n",
    "# Define the input and previous hidden state\n",
    "X = np.array([0.5, -0.2, 0.1])  # Example input vector (3-dimensional)\n",
    "h_prev = np.array([0.0, 0.0])   # Initial hidden state (2-dimensional)\n",
    "\n",
    "# Random weights and biases\n",
    "Wz = np.random.randn(input_size, hidden_size)  # Update gate weights\n",
    "Wr = np.random.randn(input_size, hidden_size)  # Reset gate weights\n",
    "Wh = np.random.randn(input_size, hidden_size)  # Candidate hidden state weights\n",
    "Uz = np.random.randn(hidden_size, hidden_size)  # Update gate recurrent weights\n",
    "Ur = np.random.randn(hidden_size, hidden_size)  # Reset gate recurrent weights\n",
    "Uh = np.random.randn(hidden_size, hidden_size)  # Candidate hidden state recurrent weights\n",
    "bz = np.zeros(hidden_size)  # Bias for update gate\n",
    "br = np.zeros(hidden_size)  # Bias for reset gate\n",
    "bh = np.zeros(hidden_size)  # Bias for candidate hidden state\n",
    "\n",
    "# GRU operations (single step)\n",
    "z = sigmoid(X.dot(Wz) + h_prev.dot(Uz) + bz)  # Update gate\n",
    "r = sigmoid(X.dot(Wr) + h_prev.dot(Ur) + br)  # Reset gate\n",
    "h_tilde = np.tanh(X.dot(Wh) + (r * h_prev).dot(Uh) + bh)  # Candidate hidden state\n",
    "h = (1 - z) * h_prev + z * h_tilde  # New hidden state\n",
    "\n",
    "# Print input, output, and hidden state update\n",
    "print(\"Input Vector (X):\", X)\n",
    "print(\"Previous Hidden State (h_prev):\", h_prev)\n",
    "print(\"Update Gate (z):\", z)\n",
    "print(\"Reset Gate (r):\", r)\n",
    "print(\"Candidate Hidden State (h_tilde):\", h_tilde)\n",
    "print(\"New Hidden State (h):\", h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
